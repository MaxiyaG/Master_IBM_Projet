# ğŸ§  Identification des Interlocuteurs par Intelligence Artificielle dans les Appels du SAMU

**Master 2 Informatique BiomÃ©dicale â€” 2024-2025**  
**Projet UE-4**

---

## ğŸ“˜ Description du projet

Ce projet a pour objectif de dÃ©velopper deux modÃ¨les dâ€™intelligence artificielle capables dâ€™**identifier automatiquement les interlocuteurs** (mÃ©decin / patient) dans les **conversations tÃ©lÃ©phoniques simulÃ©es du SAMU**.

Deux approches complÃ©mentaires ont Ã©tÃ© mises en Å“uvre :
- ğŸ§© **Approche classique** : RÃ©gression Logistique + TF-IDF
- ğŸ¤– **Approche Deep Learning** : CamemBERT (modÃ¨le BERT francophone)

Les modÃ¨les ont Ã©tÃ© Ã©valuÃ©s sur leur **taux de prÃ©cision**, avec un objectif minimal de **80 %**.

---

## ğŸ§ª Partie 1 : Ã‰valuation de MÃ©thodes dâ€™Apprentissage (Jeu de donnÃ©es Iris)

Avant de passer au traitement du langage, une Ã©tude comparative a Ã©tÃ© menÃ©e entre deux algorithmes sur le jeu de donnÃ©es **Iris** :
- ğŸŒ² **Random Forest (supervisÃ©)**
- ğŸ“Š **K-Means (non supervisÃ©)**

**RÃ©sultat :**  
Le **Random Forest** surpasse largement le **K-Means**, atteignant entre **80 % et 100 % de prÃ©cision**, dÃ©montrant la supÃ©rioritÃ© des mÃ©thodes supervisÃ©es lorsque les Ã©tiquettes sont connues.

---

## ğŸ’¬ Partie 2 : Traitement Automatique des Langues (TAL)

### ğŸ¯ Objectif

DÃ©terminer automatiquement si une phrase dâ€™un appel au SAMU est prononcÃ©e par :
- un **MÃ©decin**
- un **Patient**

---

## ğŸ“‚ Jeu de donnÃ©es

- **Nom :** [SimSamu](https://huggingface.co/datasets/medkit/simsamu)
- **Source :** [HuggingFace](https://huggingface.co/datasets/medkit/simsamu)
- **Structure :**
  - Fichiers `.srt` : transcriptions textuelles (avec timestamps)
  - Fichiers `.rttm` : identitÃ© des interlocuteurs (avec timestamps)

Les deux sources ont Ã©tÃ© **fusionnÃ©es** afin de crÃ©er un **dataset structurÃ©** oÃ¹ chaque phrase est associÃ©e Ã  lâ€™interlocuteur correspondant.

ğŸ“¦ RÃ©fÃ©rentiel du dataset : [https://github.com/manalland/simsamu](https://github.com/manalland/simsamu)

---

## âš™ï¸ PrÃ©traitement

- Nettoyage du texte (suppression des caractÃ¨res non alphabÃ©tiques et mots inutiles : *heu, bah, etc.*)
- Passage en minuscules
- Vectorisation avec **TF-IDF**
- CrÃ©ation dâ€™une matrice **3061 Ã— 2625** (phrases Ã— termes)

---

## ğŸ§© ModÃ¨le Classique : RÃ©gression Logistique

- **EntrÃ©es** : Matrice TF-IDF
- **Pipeline** :
  1. SÃ©lection des caractÃ©ristiques via **pÃ©nalisation L1**
  2. Classification avec **RÃ©gression Logistique**
- **Optimisation** : `GridSearchCV` pour le rÃ©glage des hyperparamÃ¨tres
- **Ã‰valuation** : Matrice de confusion + mÃ©triques de performance

**RÃ©sultats :**
| Classe   | PrÃ©cision | Rappel | F1-score |
|----------|------------|---------|-----------|
| MÃ©decin  | 0.79       | 0.86    | 0.82      |
| Patient  | 0.83       | 0.74    | 0.78      |

ğŸ“ˆ **PrÃ©cision globale : 80,42 %**

---

## ğŸ¤– ModÃ¨le Deep Learning : CamemBERT (BERT Francophone)

- **Base :** `CamemBERTForSequenceClassification`
- **Encodage :** Tokenizer CamemBERT, max length = 128
- **Optimiseur :** `AdamW`
- **Fonction de perte :** `CrossEntropyLoss`
- **Techniques :** RÃ©gulation par tempÃ©rature, prompts contextuels

### ğŸ§  Prompts testÃ©s :
- `default`  
- `question`  
- `contexte`  
- `rÃ´le`  

Chaque prompt testÃ© Ã  trois tempÃ©ratures : `0.5`, `1.0`, `2.0`.

**Meilleur rÃ©sultat :**
- Prompt : `default`
- TempÃ©rature : `2.0`
- ğŸ¯ **PrÃ©cision : 82,71 %**

**Pire rÃ©sultat :**
- Prompt : `question`
- TempÃ©rature : `0.5`
- âš ï¸ **PrÃ©cision : 59,05 %**

---

## ğŸ“Š Comparaison des ModÃ¨les

| ModÃ¨le | Approche | PrÃ©cision | Points forts | Limites |
|--------|-----------|------------|--------------|----------|
| RÃ©gression Logistique | Classique (TF-IDF) | 80.42 % | RapiditÃ©, simplicitÃ© | Moins sensible au contexte |
| CamemBERT | Deep Learning | 82.71 % | ComprÃ©hension contextuelle | Ressources Ã©levÃ©es |

**Conclusion :**  
CamemBERT est **plus prÃ©cis** grÃ¢ce Ã  sa capacitÃ© Ã  saisir les nuances linguistiques, tandis que la rÃ©gression logistique reste **rapide et robuste** sur des donnÃ©es limitÃ©es.

---

## ğŸš€ Environnement Technique

- ğŸ’» **Plateforme** : Google Colab
- âš™ï¸ **GPU** : NVIDIA Tesla (accÃ¨s gratuit limitÃ©)
- ğŸ **Langage** : Python 3
- ğŸ“š **Librairies principales** :
  - `scikit-learn`
  - `pandas`
  - `numpy`
  - `matplotlib`
  - `transformers`
  - `torch`
  - `huggingface_hub`

---

## ğŸ”® Perspectives dâ€™AmÃ©lioration

- ğŸ” **Augmenter la taille du dataset** (Ã©quilibrer les classes)
- ğŸ§© **Affiner CamemBERT** avec un vocabulaire mÃ©dical plus riche
- âš–ï¸ **Ajuster la pondÃ©ration** pour rÃ©duire le biais sur la classe majoritaire
- ğŸ‘¥ **Ã‰tendre la classification** Ã  dâ€™autres rÃ´les : *conjoint, parent, enfant, patient-mÃ©decinâ€¦*

---

## ğŸ“š RÃ©fÃ©rences

- ğŸ§¾ Dataset : [SimSamu â€“ HuggingFace](https://huggingface.co/datasets/medkit/simsamu)  
- ğŸ“¦ Repo GitHub du dataset : [https://github.com/manalland/simsamu](https://github.com/manalland/simsamu)  
- ğŸ¤— Documentation CamemBERT : [CamemBERT â€“ HuggingFace](https://huggingface.co/docs/transformers/en/model_doc/camembert)  
- ğŸ“˜ Article sur TF-IDF : [Medium â€“ Claude Feldges](https://medium.com/@claude.feldges/text-classification-with-tf-idf-lstm-bert-a-quantitative-comparison-b8409b556cb3)

---

## ğŸ‘¤ Auteurs

Projet rÃ©alisÃ© dans le cadre du **Master 2 Informatique BiomÃ©dicale**, UE-4, annÃ©e **2024â€“2025**.  
EncadrÃ© par lâ€™Ã©quipe pÃ©dagogique du parcours.

---
